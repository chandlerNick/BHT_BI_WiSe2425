{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storm Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48595, 58)\n",
      "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
      "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
      "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
      "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
      "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
      "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
      "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
      "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
      "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
      "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
      "       'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
      "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'LAST_MOD_DATE',\n",
      "       'LAST_MOD_TIME', 'LAST_CERT_DATE', 'LAST_CERT_TIME', 'LAST_MOD',\n",
      "       'LAST_CERT', 'ADDCORR_FLG', 'ADDCORR_DATE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./../Data/Stormdata_2006.csv', encoding='iso-8859-1')\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48595, 58)\n",
      "min: 2006-01-01 00:00:00 \n",
      "max: 2006-10-27 21:00:00\n",
      "(25734, 58)\n",
      "min: 2006-01-01 00:00:00 \n",
      "max: 2006-05-31 23:59:00\n"
     ]
    }
   ],
   "source": [
    "# Convert start and end dates to date time\n",
    "df['END_DATE_TIME'] = pd.to_datetime(df['END_DATE_TIME'])\n",
    "df['BEGIN_DATE_TIME'] = pd.to_datetime(df['BEGIN_DATE_TIME'])\n",
    "\n",
    "print(df.shape)\n",
    "print(\"min:\", min(df['BEGIN_DATE_TIME']), \"\\nmax:\", max(df['END_DATE_TIME']))\n",
    "\n",
    "# Remove those ending after our AOL database - Those before could be ok?\n",
    "df = df[df['END_DATE_TIME'] <= '2006-06-01 00:00:00']\n",
    "\n",
    "print(df.shape)\n",
    "print(\"min:\", min(df['BEGIN_DATE_TIME']), \"\\nmax:\", max(df['END_DATE_TIME']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROLAP Query possibilities:\n",
    "\n",
    "# Count the number of queries on each day, month\n",
    "```\n",
    "SELECT T.BEGIN_MONTH, T.BEGIN_DAY, SUM(*)\n",
    "FROM Storm_Table T, QUERY_TIME_TABLE Q\n",
    "WHERE Q.Day = T.BEGIN_DAY AND Q.Query IS NOT NULL\n",
    "GROUP BY ROLLUP (T.BEGIN_MONTH, T.BEGIN_DAY)\n",
    "```\n",
    "\n",
    "# Count the number of storm events beginning on each day, month\n",
    "```\n",
    "SELECT T.BEGIN_MONTH, T.BEGIN_DAY, SUM(*)\n",
    "FROM Storm_Table T\n",
    "GROUP BY ROLLUP (T.BEGIN_MONTH, T.BEGIN_DAY)\n",
    "```\n",
    "\n",
    "\n",
    "# Obtain the Queries that occur during a natural disaster\n",
    "```\n",
    "SELECT Q.Query, Q.DATE_TIME\n",
    "FROM Storm_Table T, QUERY_TIME_TABLE Q\n",
    "WHERE \n",
    "    Q.Query IS NOT NULL\n",
    "GROUP BY\n",
    "    Q.Query,\n",
    "    Q.DATE_TIME\n",
    "HAVING Q.DATE_TIME BETWEEN T.BEGIN_DATE_TIME AND T.END_DATE_TIME\n",
    "```\n",
    "\n",
    "# Obtain the Queries that occur during a Tornado\n",
    "```\n",
    "SELECT Q.Query, Q.DATE_TIME\n",
    "FROM \n",
    "    QUERY_TIME_TABLE Q,\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM Storm_Table N\n",
    "        WHERE N.EVENT_TYPE = 'Tornado'  -- Can change this line to look at those with damage high cost or injuries too\n",
    "    ) T\n",
    "WHERE \n",
    "    Q.Query IS NOT NULL\n",
    "GROUP BY\n",
    "    Q.Query,\n",
    "    Q.DATE_TIME\n",
    "HAVING Q.DATE_TIME BETWEEN T.BEGIN_DATE_TIME AND T.END_DATE_TIME\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Specific Question:\n",
    "During the event (and 2 weeks after) are people searching things related to the event? (How do we find the keywords associated with this? Any queries containing the 'event type' string?)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
      "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
      "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
      "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
      "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
      "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
      "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
      "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
      "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
      "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
      "       'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
      "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'LAST_MOD_DATE',\n",
      "       'LAST_MOD_TIME', 'LAST_CERT_DATE', 'LAST_CERT_TIME', 'LAST_MOD',\n",
      "       'LAST_CERT', 'ADDCORR_FLG', 'ADDCORR_DATE'],\n",
      "      dtype='object')\n",
      "(25734, 58)\n",
      "36\n",
      "['Drought' 'WINTER WEATHER' 'Heat' 'Flood' 'High Surf' 'Winter Storm'\n",
      " 'High Wind' 'Wildfire' 'Heavy Snow' 'Ice Storm' 'Debris Flow'\n",
      " 'Heavy Rain' 'Strong Wind' 'Avalanche' 'Hail' 'Tornado'\n",
      " 'Marine Thunderstorm Wind' 'Winter Weather' 'Flash Flood'\n",
      " 'Thunderstorm Wind' 'Lightning' 'Marine High Wind' 'Funnel Cloud'\n",
      " 'Coastal Flood' 'Dense Fog' 'Cold/Wind Chill' 'Frost/Freeze' 'Waterspout'\n",
      " 'Storm Surge/Tide' 'Blizzard' 'Lake-Effect Snow' 'Dust Storm'\n",
      " 'Rip Current' 'Sleet' 'Marine Hail' 'Dust Devil']\n",
      "Tornadoes:  705\n",
      "Wildfires:  191\n"
     ]
    }
   ],
   "source": [
    "# More Exploration\n",
    "\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "print(df['EVENT_TYPE'].nunique())  # 36 unique event types\n",
    "print(df['EVENT_TYPE'].unique())\n",
    "\n",
    "# Most seem to be boring, look at wildfires & tornadoes\n",
    "\n",
    "print(\"Tornadoes: \", len(df[df['EVENT_TYPE'] == 'Tornado']))  # number of tornado events (705)\n",
    "print(\"Wildfires: \", len(df[df['EVENT_TYPE'] == 'Wildfire']))  # number of wildfire events (191)\n",
    "\n",
    "tornado_df = df[df['EVENT_TYPE'] == 'Tornado']\n",
    "wildfire_df = df[df['EVENT_TYPE'] == 'Wildfire']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre shapes:\n",
      "\n",
      "Tornado: (705, 58)\n",
      "Wildfire: (191, 58)\n",
      "Post shapes:\n",
      "\n",
      "Tornado: (705, 44)\n",
      "Wildfire: (191, 29)\n"
     ]
    }
   ],
   "source": [
    "# Drop the columns which contain only NAs for both of the dataframes\n",
    "\n",
    "print(f\"Pre shapes:\\n\\nTornado: {tornado_df.shape}\\nWildfire: {wildfire_df.shape}\\n\")\n",
    "\n",
    "tornado_df = tornado_df.dropna(axis = 1, how = 'all')\n",
    "wildfire_df = wildfire_df.dropna(axis = 1, how = 'all')\n",
    "\n",
    "print(f\"Post shapes:\\n\\nTornado: {tornado_df.shape}\\nWildfire: {wildfire_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
      "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
      "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
      "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
      "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
      "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
      "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'TOR_F_SCALE', 'TOR_LENGTH', 'TOR_WIDTH',\n",
      "       'BEGIN_RANGE', 'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE',\n",
      "       'END_AZIMUTH', 'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT',\n",
      "       'END_LON', 'EPISODE_NARRATIVE', 'EVENT_NARRATIVE'],\n",
      "      dtype='object')\n",
      "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
      "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
      "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
      "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
      "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
      "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
      "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the remaining cols\n",
    "print(tornado_df.columns)\n",
    "print(wildfire_df.columns)\n",
    "\n",
    "# Save the dataframes as csvs in the data directory\n",
    "tornado_df.to_csv('./../Data/TornadoEventData.csv', index = False)\n",
    "wildfire_df.to_csv('./../Data/WildfireEventData.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDSP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
